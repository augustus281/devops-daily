{
  "id": "system-design-quiz",
  "title": "System Design Fundamentals Quiz",
  "description": "Master scalable architecture patterns and distributed systems design with real-world scenarios",
  "category": "System Design",
  "icon": "Code",
  "totalPoints": 102,
  "theme": {
    "primaryColor": "indigo",
    "gradientFrom": "from-indigo-500",
    "gradientTo": "to-purple-600"
  },
  "metadata": {
    "estimatedTime": "18-22 minutes",
    "difficultyLevels": {
      "beginner": 3,
      "intermediate": 4,
      "advanced": 2
    },
    "createdDate": "2024-11-01"
  },
  "questions": [
    {
      "id": "load-balancing-basics",
      "title": "Distributing Traffic",
      "description": "Your web application receives 10,000 requests per second. How do you distribute traffic across multiple servers?",
      "situation": "You have 5 application servers and need to ensure even traffic distribution while handling server failures gracefully.",
      "codeExample": "# Current setup:\n# - 5 web servers\n# - 10,000 req/s\n# - Need: High availability and even distribution",
      "options": [
        "Use a load balancer (like NGINX or AWS ALB) with health checks and round-robin or least-connections algorithm",
        "Use DNS round-robin to distribute traffic",
        "Hard-code different server IPs in the client application",
        "Have users manually choose which server to connect to"
      ],
      "correctAnswer": 0,
      "explanation": "Load balancers provide health checking, session persistence, SSL termination, and intelligent routing algorithms. They can automatically remove failed servers from rotation and distribute traffic based on current load, unlike DNS round-robin which caches IPs and can't react to failures quickly.",
      "hint": "What solution provides automatic health checking and can instantly route around failures?",
      "difficulty": "beginner",
      "points": 10
    },
    {
      "id": "caching-strategy",
      "title": "Reducing Database Load",
      "description": "Your database is overwhelmed with read queries. 80% of queries request the same data repeatedly.",
      "situation": "Product catalog data changes infrequently but is read thousands of times per minute. Database CPU is at 95%.",
      "codeExample": "# Problem:\n# - 5,000 reads/min to product_catalog table\n# - Data changes once per hour\n# - DB CPU at 95%",
      "options": [
        "Add more database replicas",
        "Upgrade to a larger database server",
        "Denormalize all database tables",
        "Implement Redis or Memcached cache layer with TTL-based expiration for frequently accessed data"
      ],
      "correctAnswer": 3,
      "explanation": "Caching frequently accessed, infrequently changing data dramatically reduces database load. Redis/Memcached can serve thousands of requests per second from memory, reducing database queries by 80-90%. This is more cost-effective than adding replicas or upgrading hardware for read-heavy workloads.",
      "hint": "What's the most cost-effective solution for data that's read often but changes rarely?",
      "difficulty": "beginner",
      "points": 12
    },
    {
      "id": "database-scaling",
      "title": "Scaling Your Database",
      "description": "Your application database has grown to handle millions of users. Write performance is degrading.",
      "situation": "Single PostgreSQL instance handling both reads and writes. Write latency increasing as data grows.",
      "options": [
        "Keep everything in one database and upgrade hardware",
        "Delete old data to keep database small",
        "Use read replicas for read traffic and implement database sharding for write scalability across multiple database nodes",
        "Switch to NoSQL and hope it scales better"
      ],
      "correctAnswer": 2,
      "explanation": "Read replicas handle read traffic, reducing load on the primary database. Sharding distributes write load across multiple databases by partitioning data (e.g., by user ID ranges or geographic region). This horizontal scaling approach handles growth better than vertical scaling (hardware upgrades) alone.",
      "hint": "How can you distribute both read and write load across multiple database instances?",
      "difficulty": "beginner",
      "points": 12
    },
    {
      "id": "cap-theorem",
      "title": "Understanding CAP Theorem",
      "description": "You're designing a global e-commerce platform. During a network partition, what can you guarantee?",
      "situation": "Your system spans multiple data centers. Network issues between data centers occur occasionally.",
      "codeExample": "# CAP Theorem states you can only have 2 of 3:\n# - Consistency (all nodes see same data)\n# - Availability (system always responds)\n# - Partition Tolerance (works despite network failures)",
      "options": [
        "During a partition, choose between Consistency (reject requests to maintain data consistency) or Availability (serve potentially stale data)",
        "You can have all three: Consistency, Availability, and Partition Tolerance",
        "CAP theorem doesn't apply to modern systems",
        "Use blockchain to solve the CAP theorem"
      ],
      "correctAnswer": 0,
      "explanation": "CAP theorem proves you can only achieve 2 of 3 guarantees. During a network partition (which you must tolerate in distributed systems), you must choose: either maintain consistency and reject some requests (CP), or remain available but risk serving stale data (AP). E-commerce often chooses AP for shopping cart, CP for payments.",
      "hint": "During a network split, what tradeoff must you make?",
      "difficulty": "intermediate",
      "points": 14
    },
    {
      "id": "message-queues",
      "title": "Asynchronous Processing",
      "description": "Users upload videos that need processing. Processing takes 10 minutes but users expect immediate response.",
      "situation": "Video processing is CPU-intensive and slow. Users should get immediate feedback, and the system must handle traffic spikes.",
      "options": [
        "Make users wait 10 minutes for processing to complete",
        "Process videos on the web server synchronously",
        "Reject uploads during high traffic periods",
        "Use a message queue (RabbitMQ, SQS, Kafka) to accept uploads immediately, process asynchronously, and notify users when complete"
      ],
      "correctAnswer": 3,
      "explanation": "Message queues decouple request acceptance from processing. Users get immediate confirmation, uploads are queued, and worker processes handle them asynchronously. This provides better UX, handles traffic spikes gracefully (queue absorbs bursts), and allows independent scaling of web and worker tiers.",
      "hint": "How do you provide immediate response while handling slow background processing?",
      "difficulty": "intermediate",
      "points": 13
    },
    {
      "id": "microservices-vs-monolith",
      "title": "Architecture Decision",
      "description": "You're starting a new project with a team of 5 developers. Should you use microservices?",
      "situation": "Early-stage startup, small team, requirements are still evolving rapidly.",
      "codeExample": "# Context:\n# - Team: 5 developers\n# - Stage: MVP development\n# - Requirements: Changing frequently\n# - Timeline: 3 months to launch",
      "options": [
        "Use microservices from day one to ensure scalability",
        "Start with a well-structured monolith, split into microservices later when team size and complexity justify it",
        "Use serverless functions for everything",
        "Build a distributed monolith (worst of both worlds)"
      ],
      "correctAnswer": 1,
      "explanation": "Monoliths are simpler to develop, test, and deploy initially. With a small team and evolving requirements, microservices add complexity without benefits: more deployment overhead, distributed debugging, network latency, and unclear service boundaries. Start monolithic with clean module boundaries, then split when organizational or technical needs justify the complexity.",
      "hint": "What's the practical choice for a small team building an MVP?",
      "difficulty": "intermediate",
      "points": 12
    },
    {
      "id": "cdn-usage",
      "title": "Global Content Delivery",
      "description": "Your application serves users worldwide. Users in Asia experience slow page loads.",
      "situation": "Web servers are in US-East. Asian users see 2-3 second page load times. Static assets (images, JS, CSS) are 5MB total.",
      "options": [
        "Deploy servers in every country",
        "Tell users to upgrade their internet connection",
        "Use a CDN (CloudFront, Cloudflare) to cache static assets globally and serve from edge locations near users",
        "Compress all files and hope it's enough"
      ],
      "correctAnswer": 2,
      "explanation": "CDNs cache static content at edge locations worldwide, serving users from nearby servers. This dramatically reduces latency by minimizing distance data travels. CDNs also offload traffic from origin servers, provide DDoS protection, and handle traffic spikes. This is far more cost-effective than deploying infrastructure globally.",
      "hint": "What service specializes in serving content from locations near your users worldwide?",
      "difficulty": "intermediate",
      "points": 11
    },
    {
      "id": "rate-limiting",
      "title": "API Protection",
      "description": "How do you protect your API from abuse while allowing legitimate users full access?",
      "situation": "Public API is being hammered by a few users making excessive requests, degrading service for others.",
      "codeExample": "# Problem:\n# - Some users: 1000s of requests/minute\n# - Normal users: 10-20 requests/minute\n# - API performance degrading",
      "options": [
        "Block all users making more than 10 requests per minute",
        "Implement rate limiting with token bucket or sliding window algorithm, return 429 status codes, and provide clear limits in documentation",
        "Remove API documentation so fewer people can use it",
        "Add CAPTCHA to every API request"
      ],
      "correctAnswer": 1,
      "explanation": "Rate limiting with token bucket or sliding window algorithms allows burst traffic while preventing sustained abuse. Return HTTP 429 with Retry-After headers to inform clients. Implement tiered limits (per user, per IP, per API key) and document limits clearly. This protects infrastructure while allowing legitimate high-volume users to request limit increases.",
      "hint": "What's the industry-standard approach for controlling API request rates?",
      "difficulty": "advanced",
      "points": 16
    },
    {
      "id": "data-consistency",
      "title": "Handling Distributed Transactions",
      "description": "In your e-commerce system, an order involves multiple services: inventory, payment, shipping. How do you ensure consistency?",
      "situation": "Order creation must: deduct inventory, charge payment, create shipping label. Any failure should roll back all changes.",
      "codeExample": "# Distributed transaction across:\n# - Inventory Service (deduct stock)\n# - Payment Service (charge card)\n# - Shipping Service (create label)\n# Need: All succeed or all fail",
      "options": [
        "Use two-phase commit (2PC) across all services",
        "Hope all services succeed and manually fix inconsistencies",
        "Use Saga pattern with compensating transactions or event-driven eventual consistency with idempotent operations",
        "Put all services in one database to use local transactions"
      ],
      "correctAnswer": 2,
      "explanation": "In microservices, distributed transactions are challenging. The Saga pattern orchestrates a sequence of local transactions, each with compensating transactions for rollback (e.g., refund payment if shipping fails). Event-driven approaches use message queues for reliability and idempotency for retries. 2PC has poor performance and availability. Avoid distributed transactions when possible through careful service boundary design.",
      "hint": "What pattern handles multi-service transactions with compensating actions for failures?",
      "difficulty": "advanced",
      "points": 18
    }
  ]
}
